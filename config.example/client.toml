# MCP Client Configuration Template
#
# Copy this file to config/client.toml and customize for your setup.
# See README.md for detailed configuration guide.
#
# NOTE: Model settings (default_provider, model, prompt_template, tools)
# are now in a separate file: model.toml

# =============================================================================
# PROVIDERS - Configure your LLM backends
# =============================================================================
#
# Supported 'type' values determine API format:
#   - "gemini", "google"  : Google Gemini API format
#   - "ollama", "localai" : Ollama local API format
#   - "openai", "anthropic", "mistral", "groq", etc. : OpenAI-compatible format
#

# Google Gemini
[[providers]]
id = "gemini"
type = "gemini"
endpoint = "https://generativelanguage.googleapis.com"
api_key = "GEMINI_API_KEY"
models = [
    { name = "gemini-2.0-flash", display_name = "Gemini 2.0 Flash" },
    { name = "gemini-2.5-pro", display_name = "Gemini 2.5 Pro" },
]

# Ollama Local
[[providers]]
id = "ollama"
type = "ollama"
endpoint = "http://127.0.0.1:11434"
models = [
    { name = "llama3", display_name = "Llama 3" },
    { name = "mistral", display_name = "Mistral" },
]

# OpenAI
[[providers]]
id = "openai"
type = "openai"
endpoint = "https://api.openai.com"
api_key = "OPENAI_API_KEY"
models = [
    { name = "gpt-4o", display_name = "GPT-4o" },
    { name = "gpt-4o-mini", display_name = "GPT-4o Mini" },
]

# Other OpenAI-compatible providers
# [[providers]]
# id = "anthropic"
# type = "anthropic"                      # Uses OpenAI-compatible format
# endpoint = "https://api.anthropic.com"
# api_key = "ANTHROPIC_API_KEY"
# api_path = "/v1/messages"               # Custom API path if needed
# models = [{ name = "claude-3-5-sonnet", display_name = "Claude 3.5 Sonnet" }]



# =============================================================================
# REST SERVER - CORS and API documentation
# =============================================================================

[server]
# REST API bind address
bind = "127.0.0.1:8080"

# CORS allowed origins (leave empty for permissive)
cors_origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
]

# API documentation servers (shown in Swagger UI)
[[server.docs]]
url = "http://localhost:8080"
description = "Local development"

# =============================================================================
# MCP SERVERS - Define your tool servers
# =============================================================================

# Example server configuration:
#
# [[servers]]
# name = "example"                    # Unique identifier
# command = "/path/to/server-binary"  # Path to executable
# args = ["--flag", "value"]          # Optional arguments
# workdir = "/working/directory"      # Optional working directory
# env = { KEY = "value" }             # Optional environment variables
